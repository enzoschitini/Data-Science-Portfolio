{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "import missingno as msno\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cross_val_score' from 'sklearn.metrics' (c:\\Users\\Enzo Schitni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report, cross_val_score\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Caricamento del dataset\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'cross_val_score' from 'sklearn.metrics' (c:\\Users\\Enzo Schitni\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Base Model\n",
    "# Caricamento del dataset\n",
    "df = pd.read_csv('DataFrame_Crédito.csv').drop(columns=['Unnamed: 0', 'id'])\n",
    "DF_ML = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Separazione delle caratteristiche e della variabile target\n",
    "y = DF_ML.default\n",
    "X = DF_ML.drop(columns='default', axis=1)\n",
    "\n",
    "# Suddivisione in set di addestramento e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# Standardizzazione delle caratteristiche\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)                   \n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Applicazione di SMOTE per il bilanciamento del dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Sostituzione di GradientBoostingClassifier con LGBMClassifier\n",
    "clf = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, \n",
    "                         max_depth=3, random_state=42)\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Previsioni sul test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Cross-Validation\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Mostra i risultati\n",
    "print(\"Accuratezza per ogni fold:\", scores)\n",
    "print(\"Accuratezza minima:\", round(min(scores) * 100, 1), \"Accuratezza massima:\", round(max(scores) * 100, 1))\n",
    "print(\"Accuratezza media:\", round(np.mean(scores * 100), 1))\n",
    "print(\"Deviazione standard dell'accuratezza:\", round(np.std(scores * 100), 1))\n",
    "\n",
    "# Crea il grafico\n",
    "mean_score = np.mean(scores)\n",
    "std_score = np.std(scores)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Grafico a barre delle accuratezze per ogni fold\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, len(scores) + 1), scores, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuratezza')\n",
    "plt.title('Accuratezza per ogni Fold')\n",
    "\n",
    "# Grafico a dispersione dell'accuratezza media e deviazione standard\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.errorbar(x=1, y=mean_score, yerr=std_score, fmt='o', color='red', \n",
    "             capsize=5, capthick=2)\n",
    "plt.xticks([1], ['Accuratezza Media'])\n",
    "plt.ylabel('Accuratezza')\n",
    "plt.title('Accuratezza Media e Deviazione Standard')\n",
    "\n",
    "# Valutazione del modello\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "0    0.160923\n",
      "1    0.138655\n",
      "Name: default, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Definir o número de clusters\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "\n",
    "# Treinar o modelo de clustering\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Adicionar a coluna de clusters ao dataset original\n",
    "df['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Verificar a distribuição de 'default' por cluster\n",
    "print(df.groupby('Cluster')['default'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pickle\\nwith open('LGBMClassifier.pkl', 'wb') as file:\\n    pickle.dump(clf, file)\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import pickle\n",
    "with open('LGBMClassifier.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df['limite_credito'] = df['limite_credito'].str.replace('.', '', regex=False)  # Remove thousand separators\\ndf['limite_credito'] = df['limite_credito'].str.replace(',', '.', regex=False)  # Replace comma with period\\ndf['limite_credito'] = df['limite_credito'].astype(float)\\n\\ndf['valor_transacoes_12m'] = df['valor_transacoes_12m'].str.replace('.', '', regex=False)  # Remove thousand separators\\ndf['valor_transacoes_12m'] = df['valor_transacoes_12m'].str.replace(',', '.', regex=False)  # Replace comma with period\\ndf['valor_transacoes_12m'] = df['valor_transacoes_12m'].astype(float)\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df['limite_credito'] = df['limite_credito'].str.replace('.', '', regex=False)  # Remove thousand separators\n",
    "df['limite_credito'] = df['limite_credito'].str.replace(',', '.', regex=False)  # Replace comma with period\n",
    "df['limite_credito'] = df['limite_credito'].astype(float)\n",
    "\n",
    "df['valor_transacoes_12m'] = df['valor_transacoes_12m'].str.replace('.', '', regex=False)  # Remove thousand separators\n",
    "df['valor_transacoes_12m'] = df['valor_transacoes_12m'].str.replace(',', '.', regex=False)  # Replace comma with period\n",
    "df['valor_transacoes_12m'] = df['valor_transacoes_12m'].astype(float)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DF_ML = pd.get_dummies(df, drop_first=True)\\nDF_ML.head()'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"DF_ML = pd.get_dummies(df, drop_first=True)\n",
    "DF_ML.head()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Configuração do ambiente do PyCaret\\nclf = setup(df, target='default', session_id=123, \\n            preprocess=True, # Faz o pré-processamento automático\\n            remove_outliers=True, # Remove outliers\\n            normalize=True, # Normaliza os dados\\n            feature_selection=True, # Seleciona características\\n            pca=True) # Reduz dimensionalidade com PCA\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Configuração do ambiente do PyCaret\n",
    "clf = setup(df, target='default', session_id=123, \n",
    "            preprocess=True, # Faz o pré-processamento automático\n",
    "            remove_outliers=True, # Remove outliers\n",
    "            normalize=True, # Normaliza os dados\n",
    "            feature_selection=True, # Seleciona características\n",
    "            pca=True) # Reduz dimensionalidade com PCA\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = create_model('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print('vc - Curva de Variação do Modelo')\\nplot_model(model, plot='vc')\\n\\nprint('auc - Curva ROC (Receiver Operating Characteristic)')\\nplot_model(model, plot='auc')\\n\\nprint('pr - Curva de Precisão-Revocação (Precision-Recall)')\\nplot_model(model, plot='pr')\\n\\nprint('rfe - Eliminação Recursiva de Características (Recursive Feature Elimination)')\\nplot_model(model, plot='rfe')\\n\\nprint('manifold - Redução de Dimensionalidade')\\nplot_model(model, plot='manifold')\\n\\nprint('error - Erro de Predição')\\nplot_model(model, plot='error')\\n\\nprint('learning - Curva de Aprendizagem')\\nplot_model(model, plot='learning') \\n\\nprint('feature - Importância das Características')\\nplot_model(model, plot='feature')\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print('vc - Curva de Variação do Modelo')\n",
    "plot_model(model, plot='vc')\n",
    "\n",
    "print('auc - Curva ROC (Receiver Operating Characteristic)')\n",
    "plot_model(model, plot='auc')\n",
    "\n",
    "print('pr - Curva de Precisão-Revocação (Precision-Recall)')\n",
    "plot_model(model, plot='pr')\n",
    "\n",
    "print('rfe - Eliminação Recursiva de Características (Recursive Feature Elimination)')\n",
    "plot_model(model, plot='rfe')\n",
    "\n",
    "print('manifold - Redução de Dimensionalidade')\n",
    "plot_model(model, plot='manifold')\n",
    "\n",
    "print('error - Erro de Predição')\n",
    "plot_model(model, plot='error')\n",
    "\n",
    "print('learning - Curva de Aprendizagem')\n",
    "plot_model(model, plot='learning') \n",
    "\n",
    "print('feature - Importância das Características')\n",
    "plot_model(model, plot='feature')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y = DF_ML.default\\nX = DF_ML.drop(columns=\\'default\\', axis=1)\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\\n#print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")\\n\\nrus = RandomUnderSampler(random_state=42)\\nX_train_res, y_train_res = rus.fit_resample(X_train, y_train)\\n\\n# Creazione del modello Random Forest\\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\\n\\n# Addestramento del modello\\nrf.fit(X_train, y_train)\\n\\n# Previsione sui dati di test\\ny_pred = rf.predict(X_test)'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"y = DF_ML.default\n",
    "X = DF_ML.drop(columns='default', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "#print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Creazione del modello Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Addestramento del modello\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Previsione sui dati di test\n",
    "y_pred = rf.predict(X_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Avaliação do modelo\\nprint(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred))\\nprint(\"\\nAccuracy Score:\")\\nprint(accuracy_score(y_test, y_pred))'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Avaliação do modelo\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
